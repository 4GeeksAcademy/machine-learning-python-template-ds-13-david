{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clasificador de imágenes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: 'train'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/test/cat\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/test/dog\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m all_images = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m random.shuffle(all_images)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m all_images[:\u001b[32m10000\u001b[39m]:  \u001b[38;5;66;03m# 5000 por clase para train\u001b[39;00m\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'train'"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "import random\n",
                "\n",
                "os.makedirs(\"data/train/cat\", exist_ok=True)\n",
                "os.makedirs(\"data/train/dog\", exist_ok=True)\n",
                "os.makedirs(\"data/test/cat\", exist_ok=True)\n",
                "os.makedirs(\"data/test/dog\", exist_ok=True)\n",
                "\n",
                "all_images = os.listdir(\"train\")\n",
                "\n",
                "random.shuffle(all_images)\n",
                "\n",
                "for img in all_images[:10000]:  # 5000 por clase para train\n",
                "    label = img.split(\".\")[0]\n",
                "    shutil.copy(f\"train/{img}\", f\"data/train/{label}/{img}\")\n",
                "\n",
                "for img in all_images[10000:12000]:  # 1000 por clase para test\n",
                "    label = img.split(\".\")[0]\n",
                "    shutil.copy(f\"train/{img}\", f\"data/test/{label}/{img}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Procesado de imágenes y visualización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1000x1000 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1000x1000 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
                "\n",
                "def mostrar_imagenes(clase, path=\"data/train\", n=9):\n",
                "    files = os.listdir(f\"{path}/{clase}\")[:n]\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    for i, file in enumerate(files):\n",
                "        img = load_img(f\"{path}/{clase}/{file}\", target_size=(200, 200))\n",
                "        plt.subplot(3, 3, i+1)\n",
                "        plt.imshow(img)\n",
                "        plt.axis(\"off\")\n",
                "    plt.suptitle(f\"Imágenes de {clase}\")\n",
                "    plt.show()\n",
                "\n",
                "mostrar_imagenes(\"cat\")\n",
                "mostrar_imagenes(\"dog\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Entreno de la red neuronal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 0 images belonging to 2 classes.\n",
                        "Found 0 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "train_datagen = ImageDataGenerator(rescale=1./255)\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "train_data = train_datagen.flow_from_directory(\n",
                "    \"data/train\",\n",
                "    target_size=(224, 224),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n",
                "\n",
                "test_data = test_datagen.flow_from_directory(\n",
                "    \"data/test\",\n",
                "    target_size=(224, 224),\n",
                "    batch_size=32,\n",
                "    class_mode='categorical'\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-20 20:27:20.373998: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-05-20 20:27:20.407723: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-05-20 20:27:20.689233: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-05-20 20:27:20.810054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1747772841.112965   12862 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1747772841.209924   12862 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1747772841.842722   12862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1747772841.842768   12862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1747772841.842774   12862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1747772841.842777   12862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-20 20:27:21.873354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "/home/vscode/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
                        "2025-05-20 20:27:27.417909: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
                "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "\n",
                "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
                "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "\n",
                "model.add(Flatten())\n",
                "model.add(Dense(128, activation='relu'))\n",
                "model.add(Dense(2, activation='softmax'))  # 2 clases: gato y perro\n",
                "\n",
                "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Entreno del modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'train_data' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m history = model.fit(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mtrain_data\u001b[49m,\n\u001b[32m      3\u001b[39m     validation_data=test_data,\n\u001b[32m      4\u001b[39m     epochs=\u001b[32m5\u001b[39m  \u001b[38;5;66;03m# Puedes usar más si tienes tiempo\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n",
                        "\u001b[31mNameError\u001b[39m: name 'train_data' is not defined"
                    ]
                }
            ],
            "source": [
                "history = model.fit(\n",
                "    train_data,\n",
                "    validation_data=test_data,\n",
                "    epochs=5  # Puedes usar más si tienes tiempo\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "\n",
                "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_loss', save_best_only=True)\n",
                "earlystop = EarlyStopping(monitor='val_loss', patience=3)\n",
                "\n",
                "model.fit(\n",
                "    train_data,\n",
                "    validation_data=test_data,\n",
                "    epochs=10,\n",
                "    callbacks=[checkpoint, earlystop]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Guardado del modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save(\"final_model.keras\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
